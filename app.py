import streamlit as st
import re
from openai import OpenAI
import PyPDF2

client = OpenAI()

st.set_page_config(page_title="AI æ•™æå®¤ Botï¼ˆå®Œå…¨ç‰ˆï¼‰", page_icon="ğŸ“š")
st.title("ğŸ“š AI æ•™æå®¤ Botï¼ˆå®Œå…¨ç‰ˆï¼‰")

tabs = st.tabs(["æ•™æPDFè¡¨ç¤º", "ç”Ÿå¾’ã®è³ªå•ã«ç­”ãˆã‚‹AI", "æ•°å¼ãƒ»è¨ˆç®—", "ã‚¤ãƒ¡ãƒ¼ã‚¸ç”Ÿæˆï¼ˆDALL-Eï¼‰"])

# --- æ•™æPDFè¡¨ç¤º ---
with tabs[0]:
    st.header("PDFæ•™æã‚’è¡¨ç¤ºã™ã‚‹")
    uploaded_file = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["pdf"])

    if uploaded_file:
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        for page in pdf_reader.pages:
            text = page.extract_text()
            st.text_area("PDFå†…å®¹", text, height=400)

# --- ç”Ÿå¾’ã®è³ªå•ã«ç­”ãˆã‚‹AI ---
with tabs[1]:
    st.header("ğŸ’¡ ç”Ÿå¾’ã®è³ªå•ã«ç­”ãˆã‚‹AI")

    user_question = st.text_input("ç”Ÿå¾’ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    if user_question:
        with st.spinner("è€ƒãˆä¸­..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": """
ã‚ãªãŸã¯ã‚„ã•ã—ãã€ã‚ã‹ã‚Šã‚„ã™ãæ•™ãˆã‚‹å…ˆç”Ÿã§ã™ã€‚æ•°å­¦ã‚„ç†ç§‘ãªã©æ•°å¼ã‚’å«ã‚€èª¬æ˜ã‚’ã™ã‚‹éš›ã¯ã€å¿…ãšä»¥ä¸‹ã®LaTeXæ•°å¼ãƒ«ãƒ¼ãƒ«è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ã«å¾“ã£ã¦ãã ã•ã„ã€‚

ã€LaTeXæ•°å¼ãƒ«ãƒ¼ãƒ«è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ã€‘

[åŸºæœ¬ãƒ«ãƒ¼ãƒ«]
- æ•°å¼ã¯å¿…ãšLaTeXãƒ¢ãƒ¼ãƒ‰ã§è¨˜è¿°ã—ã€$ ï½ $ ã§å›²ã£ã¦ãã ã•ã„ã€‚
- LaTeXå†…ã®è¨˜å·ï¼ˆ \\[ ã‚„ \\( ãªã©ï¼‰ã¯ä¸è¦ã§ã™ã€‚streamlitã§ã¯ $ ï½ $ ã§å›²ã‚€ã ã‘ã§æ­£ã—ãè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
- ç°¡å˜ãªè¨˜è¿°ï¼ˆåˆ†æ•°ãƒ»æ›ã‘ç®—ãƒ»ã¹ãä¹—ãªã©ï¼‰ã¯ã€æ–‡ç« ä¸­ã§ã‚‚è‰¯ã„ã§ã™ãŒã€åˆ†æ•°ã‚„æ›ã‘ç®—ã€æŒ‡æ•°ãªã©ã¯å¿…ãšLaTeXã‚’ä½¿ã„ã¾ã™ã€‚

[æ•°å¼ã®æ›¸ãæ–¹ä¾‹]
- åˆ†æ•° â†’ $ \\frac{a}{b} $
- æ›ã‘ç®— â†’ $ a \\times b $
- æŒ‡æ•° â†’ $ x^2 $
- ä¸‰è§’å½¢ã®é¢ç© â†’ $ S = \\frac{1}{2} \\times åº•è¾º \\times é«˜ã• $

[æ–‡ç« ã¨æ•°å¼ã®çµ„ã¿åˆã‚ã›]
- æ–‡ç« ä¸­ã«æ•°å¼ã‚’å…¥ã‚Œã‚‹å ´åˆã‚‚ã€æ•°å¼éƒ¨åˆ†ã ã‘ã‚’ $ ï½ $ ã§å›²ã‚“ã§ãã ã•ã„ã€‚

[è£œè¶³]
- è¤‡é›‘ã™ãã‚‹æ•°å¼ã¯ LaTeX ã§ãªãæ–‡ç« ã§ã‚‚ã‚ˆã„ã§ã™ãŒã€ã§ãã‚‹ã ã‘LaTeXå„ªå…ˆã§ã€‚
"""},

                    {"role": "user", "content": user_question}
                ]
            )

            answer = response.choices[0].message.content

            # LaTeXéƒ¨åˆ†ã‚’åˆ†é›¢ã—ã¦è¡¨ç¤º
            parts = re.split(r'(\$.*?\$)', answer)
            for part in parts:
                if re.match(r'^\$.*\$$', part):
                    st.latex(part.strip('$'))
                else:
                    st.write(part)

# --- æ•°å¼ãƒ»è¨ˆç®—ã‚¿ãƒ– ---
with tabs[2]:
    st.header("âœï¸ æ•°å¼ã‚„è¨ˆç®—ã‚’AIã«èã")

    calc_question = st.text_input("æ•°å¼ãƒ»è¨ˆç®—ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

    if calc_question:
        with st.spinner("è€ƒãˆä¸­..."):
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ã‚„ã•ã—ãã€ã‚ã‹ã‚Šã‚„ã™ãæ•™ãˆã‚‹å…ˆç”Ÿã§ã™ã€‚æ•°å¼ã¯å¿…ãšLaTeXãƒ¢ãƒ¼ãƒ‰ï¼ˆ$ ï½ $ï¼‰ã§æ›¸ã„ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": calc_question}
                ]
            )

            answer = response.choices[0].message.content

            parts = re.split(r'(\$.*?\$)', answer)
            for part in parts:
                if re.match(r'^\$.*\$$', part):
                    st.latex(part.strip('$'))
                else:
                    st.write(part)

# --- ç”»åƒç”Ÿæˆï¼ˆDALL-Eï¼‰ ---
with tabs[3]:
    st.header("ğŸ¨ ç”»åƒç”Ÿæˆ (DALL-E)")

    dalle_prompt = st.text_input("ç”Ÿæˆã—ãŸã„ç”»åƒã‚’èª¬æ˜ã—ã¦ãã ã•ã„")

    if dalle_prompt:
        with st.spinner("ç”»åƒç”Ÿæˆä¸­..."):
            response = client.images.generate(
                model="dall-e-3",
                prompt=dalle_prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            image_url = response.data[0].url
            st.image(image_url, caption="ç”Ÿæˆã•ã‚ŒãŸç”»åƒ", use_column_width=True)
